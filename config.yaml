# TODO: add papers by configuration file
base_url: "https://arxiv.paperswithcode.com/api/v0/papers/"
user_name: "20bytes"
repo_name: "vlm-arxiv-daily"
show_authors: True
show_links: True
show_badge: True
max_results: 10

# DeepSeek translation (title only)
translate_title: True
deepseek_base_url: "https://api.deepseek.com"
deepseek_model: "deepseek-chat"
translation_cache_path: "./docs/title_translations.json"

publish_readme: True
publish_gitpage: True
publish_wechat: False

# file paths
json_readme_path: './docs/cv-arxiv-daily.json'
json_gitpage_path: './docs/cv-arxiv-daily-web.json'
json_wechat_path: './docs/cv-arxiv-daily-wechat.json'

md_readme_path: 'README.md'
md_gitpage_path: './docs/index.html'
md_wechat_path: './docs/wechat.md'

# keywords to search
keywords:
  "VLA":
    filters:
      - "Vision-Language-Action"
      - "Generalist Robot Policy"
      - "Robotic Manipulation"
      - "Embodied AI"
      - "Vision-Language Robot Learning"
  "VLN":
    filters:
      - "Vision-Language Navigation"
      - "Instruction-Following Navigation"
      - "Embodied Navigation"
      - "Object-Goal Navigation"
      - "Vision-and-Language Navigation"
  "VLM":
    filters:
      - "Vision-Language Model"
      - "Large Multimodal Model"
      - "Multimodal Large Language Model"
      - "Vision-Language Pre-training"
      - "Multimodal Instruction Tuning"
