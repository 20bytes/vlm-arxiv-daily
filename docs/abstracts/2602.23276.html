<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays</h1>
      <h2>Abstract (EN)</h2>
      <p>Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-turn dialogue benchmark with 1,946 dialogues across 12 diagnostic tasks, and show that CXReasonAgent produces faithfully grounded responses, enabling more reliable and verifiable diagnostic reasoning than LVLMs. These findings highlight the importance of integrating clinically grounded diagnostic tools, particularly in safety-critical clinical settings.</p>
      <h2>摘要 (ZH)</h2>
      <p>胸部X光在胸部疾病诊断中扮演核心角色，其解读本质上需要多步骤、基于证据的推理。然而，大型视觉语言模型（LVLMs）常生成看似合理但未忠实基于诊断证据的回应，且提供的可验证视觉证据有限，同时需昂贵重训练以支持新诊断任务，这限制了其在临床环境中的可靠性与适应性。为应对这些局限，我们提出CXReasonAgent，一种诊断智能体，它将大型语言模型（LLM）与临床诊断工具相结合，利用图像衍生的诊断和视觉证据进行基于证据的诊断推理。为评估这些能力，我们引入了CXReasonDial，一个包含12项诊断任务、1,946个对话的多轮对话基准，并证明CXReasonAgent能生成忠实基于证据的回应，相比LVLMs实现更可靠且可验证的诊断推理。这些发现凸显了整合临床诊断工具的重要性，尤其是在安全关键的临床环境中。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
