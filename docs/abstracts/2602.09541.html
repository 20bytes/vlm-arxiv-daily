<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>Scalpel: Fine-Grained Alignment of Attention Activation Manifolds via Mixture Gaussian Bridges to Mitigate Multimodal Hallucination</h1>
      <h2>Abstract (EN)</h2>
      <p>Rapid progress in large vision-language models (LVLMs) has achieved unprecedented performance in vision-language tasks. However, due to the strong prior of large language models (LLMs) and misaligned attention across modalities, LVLMs often generate outputs inconsistent with visual content - termed hallucination. To address this, we propose \textbf{Scalpel}, a method that reduces hallucination by refining attention activation distributions toward more credible regions. Scalpel predicts trusted attention directions for each head in Transformer layers during inference and adjusts activations accordingly. It employs a Gaussian mixture model to capture multi-peak distributions of attention in trust and hallucination manifolds, and uses entropic optimal transport (equivalent to Schrödinger bridge problem) to map Gaussian components precisely. During mitigation, Scalpel dynamically adjusts intervention strength and direction based on component membership and mapping relationships between hallucination and trust activations. Extensive experiments across multiple datasets and benchmarks demonstrate that Scalpel effectively mitigates hallucinations, outperforming previous methods and achieving state-of-the-art performance. Moreover, Scalpel is model- and data-agnostic, requiring no additional computation, only a single decoding step.</p>
      <h2>摘要 (ZH)</h2>
      <p>大型视觉语言模型（LVLMs）的快速发展已在视觉语言任务中实现了前所未有的性能。然而，由于大型语言模型（LLMs）的强大先验以及跨模态注意力未对齐，LVLMs常生成与视觉内容不一致的输出——即幻觉现象。为解决此问题，我们提出\textbf{Scalpel}方法，通过将注意力激活分布细化至更可信区域来减少幻觉。Scalpel在推理过程中预测Transformer各层中每个注意力头的可信方向，并相应调整激活值。该方法采用高斯混合模型捕捉信任与幻觉流形中注意力的多峰分布，并利用熵最优传输（等价于薛定谔桥问题）精确映射高斯分量。在缓解过程中，Scalpel根据分量隶属度及幻觉与信任激活间的映射关系，动态调整干预强度与方向。在多个数据集和基准上的广泛实验表明，Scalpel能有效缓解幻觉，性能超越现有方法，达到最先进水平。此外，Scalpel具有模型与数据无关性，无需额外计算，仅需单步解码即可完成。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
