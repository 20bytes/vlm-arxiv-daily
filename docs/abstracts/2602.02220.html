<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation&lt;br&gt;LangMap：面向开放词汇目标导航的分层基准&lt;br&gt;[摘要](abstracts/2602.02220.html)</h1>
      <h2>Abstract (EN)</h2>
      <p>The relationships between objects and language are fundamental to meaningful communication between humans and AI, and to practically useful embodied intelligence. We introduce HieraNav, a multi-granularity, open-vocabulary goal navigation task where agents interpret natural language instructions to reach targets at four semantic levels: scene, room, region, and instance. To this end, we present Language as a Map (LangMap), a large-scale benchmark built on real-world 3D indoor scans with comprehensive human-verified annotations and tasks spanning these levels. LangMap provides region labels, discriminative region descriptions, discriminative instance descriptions covering 414 object categories, and over 18K navigation tasks. Each target features both concise and detailed descriptions, enabling evaluation across different instruction styles. LangMap achieves superior annotation quality, outperforming GOAT-Bench by 23.8% in discriminative accuracy using four times fewer words. Comprehensive evaluations of zero-shot and supervised models on LangMap reveal that richer context and memory improve success, while long-tailed, small, context-dependent, and distant goals, as well as multi-goal completion, remain challenging. HieraNav and LangMap establish a rigorous testbed for advancing language-driven embodied navigation. Project: https://bo-miao.github.io/LangMap</p>
      <h2>摘要 (ZH)</h2>
      <p>物体与语言之间的关系对于人类与人工智能之间的有意义交流以及实际有用的具身智能至关重要。我们引入了HieraNav，一个多粒度、开放词汇的目标导航任务，其中智能体通过解析自然语言指令，在四个语义层级上到达目标：场景、房间、区域和实例。为此，我们提出了Language as a Map（LangMap），这是一个基于真实世界3D室内扫描的大规模基准，包含全面的人工验证标注和覆盖这些层级的任务。LangMap提供区域标签、区分性区域描述、涵盖414个对象类别的区分性实例描述，以及超过18K个导航任务。每个目标都配有简洁和详细的描述，支持不同指令风格的评估。LangMap实现了卓越的标注质量，在区分性准确率上比GOAT-Bench高出23.8%，同时使用的词汇量减少了四倍。在LangMap上对零样本和监督模型的综合评估表明，更丰富的上下文和记忆能提高成功率，而长尾、小型、上下文依赖和远距离目标，以及多目标完成，仍然是挑战。HieraNav和LangMap为推进语言驱动的具身导航建立了一个严谨的测试平台。项目地址：https://bo-miao.github.io/LangMap</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
