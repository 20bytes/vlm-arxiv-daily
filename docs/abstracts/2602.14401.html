<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>pFedNavi: Structure-Aware Personalized Federated Vision-Language Navigation for Embodied AI</h1>
      <h2>Abstract (EN)</h2>
      <p>Vision-Language Navigation VLN requires large-scale trajectory instruction data from private indoor environments, raising significant privacy concerns. Federated Learning FL mitigates this by keeping data on-device, but vanilla FL struggles under VLNs&#x27; extreme cross-client heterogeneity in environments and instruction styles, making a single global model suboptimal. This paper proposes pFedNavi, a structure-aware and dynamically adaptive personalized federated learning framework tailored for VLN. Our key idea is to personalize where it matters: pFedNavi adaptively identifies client-specific layers via layer-wise mixing coefficients, and performs fine-grained parameter fusion on the selected components (e.g., the encoder-decoder projection and environment-sensitive decoder layers) to balance global knowledge sharing with local specialization. We evaluate pFedNavi on two standard VLN benchmarks, R2R and RxR, using both ResNet and CLIP visual representations. Across all metrics, pFedNavi consistently outperforms the FedAvg-based VLN baseline, achieving up to 7.5% improvement in navigation success rate and up to 7.8% gain in trajectory fidelity, while converging 1.38x faster under non-IID conditions.</p>
      <h2>摘要 (ZH)</h2>
      <p>视觉语言导航（VLN）需要来自私有室内环境的大规模轨迹指令数据，这引发了显著的隐私担忧。联邦学习（FL）通过将数据保留在设备端来缓解这一问题，但传统的FL在VLN中面临环境和指令风格的极端跨客户端异构性挑战，导致单一的全局模型效果不佳。本文提出了pFedNavi，一种专为VLN设计的结构感知且动态自适应的个性化联邦学习框架。我们的核心思想是在关键处实现个性化：pFedNavi通过分层混合系数自适应地识别客户端特定层，并对选定组件（如编码器-解码器投影层和环境敏感的解码器层）执行细粒度参数融合，以平衡全局知识共享与本地专业化。我们在两个标准VLN基准测试R2R和RxR上评估了pFedNavi，使用了ResNet和CLIP两种视觉表示。在所有指标上，pFedNavi均一致优于基于FedAvg的VLN基线，导航成功率提升高达7.5%，轨迹保真度增益高达7.8%，同时在非独立同分布条件下收敛速度加快1.38倍。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
