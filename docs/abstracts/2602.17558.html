<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>RetouchIQ: MLLM Agents for Instruction-Based Image Retouching with Generalist Reward&lt;br&gt;RetouchIQ：基于指令的图像修饰多模态大语言模型智能体与通用奖励机制&lt;br&gt;[摘要](abstracts/2602.17558.html)</h1>
      <h2>Abstract (EN)</h2>
      <p>Abstract not available.</p>
      <h2>摘要 (ZH)</h2>
      <p>多模态大语言模型（MLLMs）的最新进展，在将视觉-语言推理能力扩展至基于专业工具的图像编辑领域方面展现出巨大潜力，实现了直观且富有创意的编辑方式。一个颇具前景的方向是利用强化学习（RL）使MLLMs能够在专业图像编辑软件中推理并执行最优工具使用方案。然而，由于缺乏能够反映创意编辑固有主观性的可靠、可验证的奖励信号，训练过程仍面临挑战。本研究提出RetouchIQ框架，该框架通过由通用奖励模型引导的MLLM智能体，实现基于指令的可执行图像编辑。RetouchIQ能够解读用户指定的编辑意图，并生成相应的可执行图像调整方案，从而在高层审美目标与精确参数控制之间建立桥梁。为超越传统基于规则、使用手工设计指标计算与固定参考图像相似度的奖励机制，我们提出一种通用奖励模型——一种经过RL微调的MLLM，能够根据具体情况通过一组生成的指标评估编辑结果。随后，该奖励模型通过多模态推理提供标量反馈，从而实现具有高质量、指令一致梯度的强化学习。我们构建了一个包含19万条指令-推理对的数据集，并建立了基于指令的图像编辑新基准。实验表明，RetouchIQ在语义一致性和感知质量上均显著优于以往基于MLLM和扩散模型的编辑系统。我们的研究结果证明了通用奖励驱动的MLLM智能体作为专业图像编辑灵活、可解释且可执行的辅助工具的潜力。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
