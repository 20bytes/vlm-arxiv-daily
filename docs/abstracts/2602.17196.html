<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models&lt;br&gt;EntropyPrune：基于矩阵熵引导的多模态大语言模型视觉令牌剪枝&lt;br&gt;[摘要](abstracts/2602.17196.html)</h1>
      <h2>Abstract (EN)</h2>
      <p>Abstract not available.</p>
      <h2>摘要 (ZH)</h2>
      <p>多模态大语言模型（MLLMs）因每张图像需处理数百个视觉令牌而产生高昂推理成本。尽管令牌剪枝已被证明能有效加速推理，但何时何地进行剪枝仍主要依赖启发式方法。现有方法通常基于静态、经验选择的层，这限制了其可解释性和跨模型的可迁移性。本研究引入矩阵熵视角，识别出“熵坍缩层”（ECL），即视觉表示的信息内容在此层出现急剧且一致的下降，从而为选择剪枝阶段提供了原则性准则。基于此观察，我们提出EntropyPrune，一种新颖的矩阵熵引导令牌剪枝框架，该框架量化单个视觉令牌的信息价值，并在不依赖注意力图的情况下剪除冗余令牌。此外，为实现高效计算，我们利用对偶格拉姆矩阵的谱等价性，降低了熵计算的复杂度，理论加速比最高可达64倍。在多样化多模态基准上的广泛实验表明，EntropyPrune在准确性和效率上均持续优于最先进的剪枝方法。在LLaVA-1.5-7B模型上，我们的方法实现了68.2%的浮点运算量（FLOPs）减少，同时保持了96.0%的原始性能。此外，EntropyPrune能有效泛化至高分辨率和基于视频的模型，凸显了其在实用MLLM加速中的强鲁棒性和可扩展性。代码将公开于https://github.com/YahongWang1/EntropyPrune。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
