<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding&lt;br&gt;LongVideo-R1：面向低成本长视频理解的智能导航方法&lt;br&gt;[摘要](abstracts/2602.20913.html)</h1>
      <h2>Abstract (EN)</h2>
      <p>Abstract not available.</p>
      <h2>摘要 (ZH)</h2>
      <p>本文针对长视频理解在低计算预算下的关键且尚未充分探索的挑战，提出了LongVideo-R1——一种具备主动推理能力的多模态大语言模型（MLLM）智能体，旨在实现高效的视频上下文导航，避免穷举搜索带来的冗余。LongVideo-R1的核心是一个推理模块，它利用高层视觉线索推断出最具信息量的视频片段以供后续处理。在推理过程中，智能体从顶层视觉摘要开始遍历，并迭代地细化其关注焦点，一旦获取足够信息以回答查询，便立即停止探索过程。为促进训练，我们首先从带有标注的视频语料库CGBench中提取层次化视频描述，并引导GPT-5生成了33K条高质量的工具增强思维链轨迹。LongVideo-R1智能体基于Qwen-3-8B模型通过两阶段范式进行微调：先进行监督微调（SFT），再进行强化学习（RL），其中RL采用专门设计的奖励函数，以最大化选择性且高效的片段导航能力。在多个长视频基准测试上的实验验证了该方法的有效性，其在问答准确性与效率之间实现了优越的权衡。所有整理的数据和源代码均提供于补充材料中，并将公开可用。代码与数据访问地址：https://github.com/qiujihao19/LongVideo-R1</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
