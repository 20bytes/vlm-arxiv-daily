<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding</h1>
      <h2>Abstract (EN)</h2>
      <p>This paper addresses the critical and underexplored challenge of long video understanding with low computational budgets. We propose LongVideo-R1, an active, reasoning-equipped multimodal large language model (MLLM) agent designed for efficient video context navigation, avoiding the redundancy of exhaustive search. At the core of LongVideo-R1 lies a reasoning module that leverages high-level visual cues to infer the most informative video clip for subsequent processing. During inference, the agent initiates traversal from top-level visual summaries and iteratively refines its focus, immediately halting the exploration process upon acquiring sufficient knowledge to answer the query. To facilitate training, we first extract hierarchical video captions from CGBench, a video corpus with grounding annotations, and guide GPT-5 to generate 33K high-quality chain-of-thought-with-tool trajectories. The LongVideo-R1 agent is fine-tuned upon the Qwen-3-8B model through a two-stage paradigm: supervised fine-tuning (SFT) followed by reinforcement learning (RL), where RL employs a specifically designed reward function to maximize selective and efficient clip navigation. Experiments on multiple long video benchmarks validate the effectiveness of name, which enjoys superior tradeoff between QA accuracy and efficiency. All curated data and source code are provided in the supplementary material and will be made publicly available. Code and data are available at: https://github.com/qiujihao19/LongVideo-R1</p>
      <h2>摘要 (ZH)</h2>
      <p>本文针对长视频理解在低计算预算下的关键且尚未充分探索的挑战，提出了LongVideo-R1——一种具备主动推理能力的多模态大语言模型（MLLM）智能体，旨在实现高效的视频上下文导航，避免穷举搜索带来的冗余。LongVideo-R1的核心是一个推理模块，它利用高层视觉线索推断出最具信息量的视频片段以供后续处理。在推理过程中，智能体从顶层视觉摘要开始遍历，并迭代地细化其关注焦点，一旦获取足够信息以回答查询，便立即停止探索过程。为促进训练，我们首先从带有标注的视频语料库CGBench中提取层次化视频描述，并引导GPT-5生成了33K条高质量的工具增强思维链轨迹。LongVideo-R1智能体基于Qwen-3-8B模型通过两阶段范式进行微调：先进行监督微调（SFT），再进行强化学习（RL），其中RL采用专门设计的奖励函数，以最大化选择性且高效的片段导航能力。在多个长视频基准测试上的实验验证了该方法的有效性，其在问答准确性与效率之间实现了优越的权衡。所有整理的数据和源代码均提供于补充材料中，并将公开可用。代码与数据访问地址：https://github.com/qiujihao19/LongVideo-R1</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
