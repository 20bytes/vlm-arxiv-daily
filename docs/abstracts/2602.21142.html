<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>LUMEN: Longitudinal Multi-Modal Radiology Model for Prognosis and Diagnosis&lt;br&gt;LUMEN：用于预后与诊断的纵向多模态放射学模型&lt;br&gt;[摘要](abstracts/2602.21142.html)</h1>
      <h2>Abstract (EN)</h2>
      <p>Abstract not available.</p>
      <h2>摘要 (ZH)</h2>
      <p>大型视觉语言模型（VLMs）已从通用应用发展到临床等专业领域，展现出在放射学决策支持中的潜力。一个前景广阔的应用是通过视觉与自然语言问答（VQA）界面分析胸部X光片（CXR）等放射影像数据，辅助放射科医生进行决策。当存在纵向影像数据时，放射科医生会分析时间变化，这对准确诊断和预后至关重要。手动纵向分析过程耗时，这促使我们开发一种能够提供预后能力的训练框架。我们提出了一种新颖的训练框架LUMEN，该框架针对纵向CXR解读进行了优化，利用多图像和多任务指令微调来提升预后与诊断性能。我们在公开可用的MIMIC-CXR及其相关Medical-Diff-VQA数据集上进行了实验。我们进一步构建了一个包含纵向研究的新型指令遵循数据集，以支持预后VQA任务的开发。我们的方法在诊断VQA任务上相比基线模型表现出显著改进，更重要的是，在预后能力方面显示出良好潜力。这些结果凸显了精心设计的指令微调VLMs在实现更准确、更具临床意义的纵向放射影像数据解读中的价值。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
