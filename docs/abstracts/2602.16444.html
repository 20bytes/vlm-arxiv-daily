<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation&lt;br&gt;RoboGene：通过多样性驱动的智能体框架提升视觉语言动作预训练，实现真实世界任务生成&lt;br&gt;[摘要](abstracts/2602.16444.html)</h1>
      <h2>Abstract (EN)</h2>
      <p>Abstract not available.</p>
      <h2>摘要 (ZH)</h2>
      <p>通用机器人操作的发展受到多样化真实世界交互数据稀缺的阻碍。与视觉或语言领域可从网络收集数据不同，机器人数据收集是一个主动过程，涉及高昂的物理成本。因此，自动化任务生成以最大化数据价值，成为一个关键但尚未充分探索的挑战。现有手动方法难以扩展且偏向常见任务，而现成的基础模型常产生物理上不可行的指令幻觉。为解决这一问题，我们提出了RoboGene，一个旨在为单臂、双臂及移动机器人自动生成多样化、物理可行的操作任务的智能体框架。RoboGene整合了三个核心组件：用于广泛任务覆盖的多样性驱动采样、强制执行物理约束的自我反思机制，以及持续改进的人机协同优化。我们进行了广泛的定量分析和大规模真实世界实验，收集了包含1.8万条轨迹的数据集，并引入了新指标以评估任务质量、可行性和多样性。结果表明，RoboGene显著优于最先进的基础模型（如GPT-4o、Gemini 2.5 Pro）。此外，真实世界实验显示，使用RoboGene预训练的视觉语言动作模型实现了更高的成功率和更优的泛化能力，凸显了高质量任务生成的重要性。项目网址：https://robogene-boost-vla.github.io。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
