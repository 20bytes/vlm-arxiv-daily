<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>Catastrophic Forgetting Resilient One-Shot Incremental Federated Learning</h1>
      <h2>Abstract (EN)</h2>
      <p>Modern big-data systems generate massive, heterogeneous, and geographically dispersed streams that are large-scale and privacy-sensitive, making centralization challenging. While federated learning (FL) provides a privacy-enhancing training mechanism, it assumes a static data flow and learns a collaborative model over multiple rounds, making learning with \textit{incremental} data challenging in limited-communication scenarios. This paper presents One-Shot Incremental Federated Learning (OSI-FL), the first FL framework that addresses the dual challenges of communication overhead and catastrophic forgetting. OSI-FL communicates category-specific embeddings, devised by a frozen vision-language model (VLM) from each client in a single communication round, which a pre-trained diffusion model at the server uses to synthesize new data similar to the client&#x27;s data distribution. The synthesized samples are used on the server for training. However, two challenges still persist: i) tasks arriving incrementally need to retrain the global model, and ii) as future tasks arrive, retraining the model introduces catastrophic forgetting. To this end, we augment training with Selective Sample Retention (SSR), which identifies and retains the top-p most informative samples per category and task pair based on sample loss. SSR bounds forgetting by ensuring that representative retained samples are incorporated into training in further iterations. The experimental results indicate that OSI-FL outperforms baselines, including traditional and one-shot FL approaches, in both class-incremental and domain-incremental scenarios across three benchmark datasets.</p>
      <h2>摘要 (ZH)</h2>
      <p>现代大数据系统产生大规模、异构且地理分散的隐私敏感流式数据，使得数据集中化处理面临挑战。尽管联邦学习（FL）提供了一种增强隐私的训练机制，但其假设数据流是静态的，并通过多轮学习协作模型，这在通信受限的场景下难以应对增量数据的学习。本文提出了单次增量联邦学习（OSI-FL），这是首个同时应对通信开销和灾难性遗忘双重挑战的FL框架。OSI-FL在单轮通信中，利用冻结的视觉语言模型（VLM）从每个客户端提取类别特定的嵌入表示，服务器端的预训练扩散模型使用这些嵌入合成与客户端数据分布相似的新数据。合成样本在服务器端用于训练。然而，仍存在两个挑战：i）增量到达的任务需要重新训练全局模型，ii）随着未来任务的到来，重新训练模型会引发灾难性遗忘。为此，我们通过选择性样本保留（SSR）增强训练，该方法基于样本损失识别并保留每个类别和任务对中最具信息量的前p个样本。SSR通过确保在后续迭代中将具有代表性的保留样本纳入训练，从而限制遗忘。实验结果表明，在三个基准数据集上的类增量和域增量场景中，OSI-FL均优于传统及单次FL基线方法。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
