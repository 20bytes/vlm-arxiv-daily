<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>CrystaL: Spontaneous Emergence of Visual Latents in MLLMs</h1>
      <h2>Abstract (EN)</h2>
      <p>Multimodal Large Language Models (MLLMs) have achieved remarkable performance by integrating powerful language backbones with large-scale visual encoders. Among these, latent Chain-of-Thought (CoT) methods enable implicit reasoning in continuous hidden states, facilitating seamless vision-language integration and faster inference. However, existing heuristically predefined supervision signals in latent CoT provide limited guidance for preserving critical visual information in intermediate latent states. To address this limitation, we propose CrystaL (Crystallized Latent Reasoning), a single-stage framework with two paths to process intact and corrupted images, respectively. By explicitly aligning the attention patterns and prediction distributions across the two paths, CrystaL crystallizes latent representations into task-relevant visual semantics, without relying on auxiliary annotations or external modules. Extensive experiments on perception-intensive benchmarks demonstrate that CrystaL consistently outperforms state-of-the-art baselines, achieving substantial gains in fine-grained visual understanding while maintaining robust reasoning capabilities.</p>
      <h2>摘要 (ZH)</h2>
      <p>多模态大语言模型（MLLMs）通过将强大的语言主干网络与大规模视觉编码器相结合，取得了显著性能。其中，潜在思维链方法能够在连续的隐藏状态中进行隐式推理，促进视觉与语言的无缝整合并加速推理过程。然而，现有潜在思维链中启发式预定义的监督信号对于在中间潜在状态中保留关键视觉信息的指导作用有限。为解决这一局限，我们提出了CrystaL（结晶化潜在推理），这是一个单阶段框架，包含两条路径分别处理完整图像和受损图像。通过显式对齐两条路径间的注意力模式和预测分布，CrystaL将潜在表征结晶为任务相关的视觉语义，无需依赖辅助标注或外部模块。在感知密集型基准测试上的大量实验表明，CrystaL始终优于最先进的基线方法，在保持强大推理能力的同时，实现了细粒度视觉理解能力的显著提升。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
