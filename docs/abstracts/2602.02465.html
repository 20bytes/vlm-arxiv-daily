<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>MentisOculi: Revealing the Limits of Reasoning with Mental Imagery</h1>
      <h2>Abstract (EN)</h2>
      <p>Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual representations in a goal-oriented manner. To evaluate and probe this capability, we develop MentisOculi, a procedural, stratified suite of multi-step reasoning problems amenable to visual solution, tuned to challenge frontier models. Evaluating visual strategies ranging from latent tokens to explicit generated imagery, we find they generally fail to improve performance. Analysis of UMMs specifically exposes a critical limitation: While they possess the textual reasoning capacity to solve a task and can sometimes generate correct visuals, they suffer from compounding generation errors and fail to leverage even ground-truth visualizations. Our findings suggest that despite their inherent appeal, visual thoughts do not yet benefit model reasoning. MentisOculi establishes the necessary foundation to analyze and close this gap across diverse model families.</p>
      <h2>摘要 (ZH)</h2>
      <p>前沿模型正从仅能接收视觉信息的多模态大语言模型（MLLMs）向能够原生交错生成内容的统一多模态模型（UMMs）转变。这一转变激发了人们利用中间可视化作为推理辅助的兴趣，类似于人类的心智意象。该理念的核心在于以目标为导向形成、维持和操纵视觉表征的能力。为了评估和探究这一能力，我们开发了MentisOculi——一套程序化、分层化的多步推理问题集，适用于视觉化解决方案，并针对前沿模型的挑战进行了优化。通过评估从潜在标记到显式生成图像等多种视觉策略，我们发现它们通常未能提升性能。对UMMs的具体分析揭示了一个关键局限：尽管它们具备解决任务的文本推理能力，有时也能生成正确的视觉内容，但它们受到生成误差累积的影响，甚至无法有效利用真实的可视化信息。我们的研究结果表明，尽管视觉思维具有内在吸引力，但目前尚未对模型推理产生助益。MentisOculi为分析和弥合不同模型家族间的这一差距奠定了必要基础。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
