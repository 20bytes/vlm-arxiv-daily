<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>LATA: Laplacian-Assisted Transductive Adaptation for Conformal Uncertainty in Medical VLMs</h1>
      <h2>Abstract (EN)</h2>
      <p>Medical vision-language models (VLMs) are strong zero-shot recognizers for medical imaging, but their reliability under domain shift hinges on calibrated uncertainty with guarantees. Split conformal prediction (SCP) offers finite-sample coverage, yet prediction sets often become large (low efficiency) and class-wise coverage unbalanced-high class-conditioned coverage gap (CCV), especially in few-shot, imbalanced regimes; moreover, naively adapting to calibration labels breaks exchangeability and voids guarantees. We propose \texttt{\textbf{LATA}} (Laplacian-Assisted Transductive Adaptation), a \textit{training- and label-free} refinement that operates on the joint calibration and test pool by smoothing zero-shot probabilities over an image-image k-NN graph using a small number of CCCP mean-field updates, preserving SCP validity via a deterministic transform. We further introduce a \textit{failure-aware} conformal score that plugs into the vision-language uncertainty (ViLU) framework, providing instance-level difficulty and label plausibility to improve prediction set efficiency and class-wise balance at fixed coverage. \texttt{\textbf{LATA}} is black-box (no VLM updates), compute-light (windowed transduction, no backprop), and includes an optional prior knob that can run strictly label-free or, if desired, in a label-informed variant using calibration marginals once. Across \textbf{three} medical VLMs and \textbf{nine} downstream tasks, \texttt{\textbf{LATA}} consistently reduces set size and CCV while matching or tightening target coverage, outperforming prior transductive baselines and narrowing the gap to label-using methods, while using far less compute. Comprehensive ablations and qualitative analyses show that \texttt{\textbf{LATA}} sharpens zero-shot predictions without compromising exchangeability.</p>
      <h2>摘要 (ZH)</h2>
      <p>医学视觉语言模型在医学影像零样本识别任务中表现优异，但其在领域偏移下的可靠性依赖于具备理论保证的校准不确定性。分形置信预测虽能提供有限样本覆盖保证，但预测集常因规模过大（效率低下）且类别间覆盖不均衡（类别条件覆盖差异高）而受限，尤其在少样本、不平衡场景中更为突出；若直接使用校准标签进行自适应，则会破坏数据交换性并导致理论保证失效。本文提出LATA（拉普拉斯辅助转导自适应），这是一种无需训练和标注的优化方法：通过对图像间k近邻图上的零样本概率进行少量连续置信传播平均场更新平滑处理，在联合校准集与测试集上操作，并通过确定性变换保持分形置信预测的有效性。我们进一步提出可感知失败的置信评分，将其嵌入视觉语言不确定性框架，通过实例级难度与标签合理性提升固定覆盖率下的预测集效率与类别均衡性。LATA具有黑盒特性（无需更新视觉语言模型）、计算轻量（窗口化转导、无需反向传播），并包含可选先验调节机制，既可完全无标注运行，也可通过单次使用校准边缘分布实现标签感知变体。在三种医学视觉语言模型与九项下游任务的实验中，LATA持续缩小预测集规模与类别条件覆盖差异，在维持或收紧目标覆盖率的同时，超越现有转导基线方法，显著逼近需使用标签的方法性能，且计算开销大幅降低。系统的消融实验与定性分析表明，LATA能在保持数据交换性的前提下有效锐化零样本预测。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
