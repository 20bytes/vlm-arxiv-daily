<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>Capturing Visual Environment Structure Correlates with Control Performance</h1>
      <h2>Abstract (EN)</h2>
      <p>The choice of visual representation is key to scaling generalist robot policies. However, direct evaluation via policy rollouts is expensive, even in simulation. Existing proxy metrics focus on the representation&#x27;s capacity to capture narrow aspects of the visual world, like object shape, limiting generalization across environments. In this paper, we take an analytical perspective: we probe pretrained visual encoders by measuring how well they support decoding of environment state -- including geometry, object structure, and physical attributes -- from images. Leveraging simulation environments with access to ground-truth state, we show that this probing accuracy strongly correlates with downstream policy performance across diverse environments and learning settings, significantly outperforming prior metrics and enabling efficient representation selection. More broadly, our study provides insight into the representational properties that support generalizable manipulation, suggesting that learning to encode the latent physical state of the environment is a promising objective for control.</p>
      <h2>摘要 (ZH)</h2>
      <p>视觉表示的选择是扩展通用机器人策略的关键。然而，即使是在仿真环境中，通过策略部署进行直接评估的成本也很高。现有的代理指标侧重于表示捕捉视觉世界狭窄方面的能力，如物体形状，这限制了跨环境的泛化能力。在本文中，我们采取分析视角：通过测量预训练视觉编码器从图像中解码环境状态（包括几何结构、物体结构和物理属性）的能力，来探究这些编码器。利用能够获取真实状态信息的仿真环境，我们证明了这种探究精度与跨不同环境和学习设置的下游策略性能高度相关，显著优于先前的指标，并实现了高效的表示选择。更广泛地说，我们的研究为支持可泛化操作的表示属性提供了见解，表明学习编码环境的潜在物理状态是实现控制的一个有前景的目标。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
