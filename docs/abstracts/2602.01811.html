<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract</title>
  <style>
    body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #f7f7f5; color: #1f2937; }
    .wrap { max-width: 900px; margin: 0 auto; padding: 28px 20px 60px; }
    .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 20px 24px; }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 20px 0 8px; }
    p { line-height: 1.6; white-space: pre-wrap; }
    a { color: #2563eb; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <h1>From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models</h1>
      <h2>Abstract (EN)</h2>
      <p>While vision-language-action (VLA) models for embodied agents integrate perception, reasoning, and control, they remain constrained by two critical weaknesses: first, during grasping tasks, the action tokens generated by the language model often exhibit subtle spatial deviations from the target object, resulting in grasp failures; second, they lack the ability to reliably recognize task completion, which leads to redundant actions and frequent timeout errors. To address these challenges and enhance robustness, we propose a lightweight, training-free framework, VLA-SCT. This framework operates as a self-correcting control loop, combining data-driven action refinement with conditional logic for termination. Consequently, compared to baseline approaches, our method achieves consistent improvements across all datasets in the LIBERO benchmark, significantly increasing the success rate of fine manipulation tasks and ensuring accurate task completion, thereby promoting the deployment of more reliable VLA agents in complex, unstructured environments.</p>
      <h2>摘要 (ZH)</h2>
      <p>尽管面向具身智能体的视觉语言动作（VLA）模型集成了感知、推理与控制能力，但仍受限于两大关键弱点：其一，在抓取任务中，语言模型生成的动作标记常与目标对象存在细微的空间偏差，导致抓取失败；其二，模型缺乏可靠的任务完成识别能力，引发冗余动作及频繁的超时错误。为应对这些挑战并提升鲁棒性，我们提出了一种轻量级、无需训练的框架VLA-SCT。该框架作为自校正控制循环运行，结合了数据驱动的动作优化与基于条件的终止逻辑。因此，相较于基线方法，我们的方案在LIBERO基准测试的所有数据集中均实现了稳定提升，显著提高了精细操作任务的成功率，并确保任务准确完成，从而推动更可靠的VLA智能体在复杂非结构化环境中的部署。</p>
      <p><a href="../index.html">← Back</a></p>
    </div>
  </div>
</body>
</html>
